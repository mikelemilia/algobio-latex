% Overview:
%   Introduzione TeX subfile for the project.
%   Each subfile MUST start with the following line
%		\documentclass[../main.tex]{subfiles}

\documentclass[../main.tex]{subfiles}

\begin{document}

\section{Introduzione} 

\subsection{Il problema: la genotipizzazione e la rilevazione di mutazioni nel genoma}

Essere in grado di studiare il DNA e analizzarne le regioni è un compito che sta diventando sempre più importante: il DNA infatti contiene informazioni genetiche essenziali per il corretto sviluppo dell'organismo; nell'ambito degli studi genetici, la scoperta e la caratterizzazione delle variazioni di sequenza nelle popolazioni umane è un'attività importante. Lo sviluppo delle tecnologie di sequenziamento, che sono più veloci e producono molti dati, sta rivoluzionando il modo in cui queste analisi vengono eseguite e, poiché la quantità di dati è cosi grande, l'informatica svolge un ruolo importante nella loro analisi. La bioinformatica, un campo di ricerca che combina informatica e biologia, ha l'obiettivo di analizzare il DNA dai dati di sequenziamento in modo efficiente con approcci computazionali. 

L'obiettivo di questo progetto è analizzare lo stato dell'arte attuale in merito al problema della ricerca di mutazioni (SNP) all'interno di un genoma utilizzando metodi che non prevedono l'uso dell'allineamento (\textit{alignment-free}/\textit{mapping-free}). In particolare questo problema viene identificato con il termine di genotipizzazione, il processo per determinare quali varianti genetiche possiede un individuo. Il nostro focus è sullo sviluppo di strumenti bioinformatici che combinano algoritmi accurati con strutture dati efficienti. \\

\noindent
Le differenze che si verificano tra i genomi di diversi individui di una determinata specie sono note come varianti genomiche: esse possono coinvolgere regioni grandi o piccole del genoma. 
In questo elaborato ci concentreremo su varianti genomiche che coinvolgono piccole regioni del genoma; in particolare ci concentreremo su SNP, Single Nucleotide Polymorphisms, che sono polimorfismi a singolo nucleotide ossia variazione rispetto ad un unico nucleotide, tale per cui l'allele polimorfico risulta presente nella popolazione in una proporzione superiore all'1\%; al di sotto di tale soglia si è soliti parlare di variante rara, SNV o Single-Nucleotide Variant in inglese, un altro tipo di mutazione. Parleremo inoltre di indel, inserzioni o eliminazioni di una o più basi consecutive all'interno del genoma; altre variazioni sono CNV, Copy Number Variation, fenomeno in cui diverse sezioni del genoma si ripetono in numero variabile e i riarrangiamenti. Invece, le mutazioni \textit{de novo} sono alterazioni che sono presenti per la prima volta in un membro della famiglia (figlio) e non nei genitori. I diversi metodi e framework progettati per effettuare la genotipizzazione solitamente si concentrano su determinati tipi di mutazioni.

Un allele è una delle possibili versioni di una variante. L'insieme degli alleli ereditati da un genitore è noto come aplotipo; poiché gli esseri umani sono organismi diploidi, ereditano due aplotipi dai due genitori, e la coppia di alleli di una variante che si verificano nei due aplotipi, in una posizione specifica, è nota come genotipo della variante. In particolare, il genotipo è detto omozigote quando i due alleli sono identici, eterozigote se i due alleli differiscono. 

La ``chiamata" delle varianti, o genotipizzazione, è il processo tramite cui vengono calcolati i genotipi di tutte le varianti supportate da un campione in input ed è un compito principale negli studi che analizzano i genomi di più individui di una popolazione per identificare varianti genomiche e la loro associazione con tratti fenotipici, come le malattie. Quando è disponibile un dataset di varianti prodotte precedentemente da questi studi, è possibile limitare il calcolo per genotipizzare solo quelle varianti (genotipizzazione, o chiamata, di varianti conosciute). Quando l'insieme di varianti non è noto a priori, le varianti devono essere prima scoperte e poi genotipizzate (scoperta di variante).

Le tecnologie di sequenziamento consentono di tradurre una molecola di DNA in una serie di stringhe, sequenze di nucleotidi, ma, a causa di limitazioni tecniche, non sono in grado di produrre una singola stringa che rappresenta l'intero DNA, ma producono frammenti, noti come read (letture), della sequenza nucleotidica. Un concetto importante relativo al sequenziamento è la coverage, definita come il numero di basi di tutte le read che corrispondono a un genoma diviso per la lunghezza di questo genoma. Attualmente le tecnologie di sequenziamento più utilizzate sono le cosiddette tecnologie di sequenziamento di nuova generazione, NGS (Next-Generation Sequencing). Queste sono state sviluppate per ridurre i tempi e i costi richiesti per eseguire un esperimento di sequenziamento e aumentare la quantità di dati prodotti da una singola seduta, che vanno da diversi milioni a miliardi di frammenti di read brevi per esperimento. Grazie all'efficienza e all'elevata quantità di dati prodotti, sono anche note come tecnologie HTS (High-Throughput Sequencing). La tecnologia NGS più adottata è la Illumina Sequencing Technology, che  supporta anche il sequenziamento dell'intero genoma. Gli svantaggi di questa sono la lunghezza delle read, che appunto vengono definite \textit{brevi}, di circa 300 bp (base pair) e il tasso di errore di  $\sim$0,1\%. Poter estrarre conoscenze significative da brevi frammenti è complesso poiché non offrono una visione completa dell'intera sequenza di DNA, l'archiviazione dei dataset non elaborati potrebbe richiedere centinaia di gigabyte di memoria e l'analisi è intensiva dal punto di vista computazionale. Ma l'efficienza ed economicità e l'alta qualità dei dati che vengono prodotti ha portato al grande utilizzo della tecnologia. I dati di sequenziamento, le read, vengono poi utilizzate come input per i diversi metodi di genotipizzazione.




\subsection{La pipeline standard e la tecnica \textit{mapping-free}}

La pipeline standard utilizzata per la scoperta e genotipizzazione delle varianti include, in prima battuta, indipendentemente dall'algoritmo sottostante, l'allineamento delle read in input con una sequenza del genoma di riferimento, anch'esso in input, cercando la corrispondenza di singole basi o amminoacidi e consentendo un certo numero di disallineamenti o indel. Ciò consente di identificare la posizione più probabile lungo il genoma di riferimento da cui proviene ciascuna read del campione di input. Le read mappate vengono quindi utilizzate per assegnare i genotipi; per valutare l'allineamento delle read in ogni posizione lungo il genoma, si utilizzano diversi strumenti di calcolo che assegnano un punteggio di confidenza per indicare la probabilità dell'esistenza di una variante. Questo si ottiene usando algoritmi di inferenza statistica, che sono necessari in quanto gli allineamenti imperfetti creano incertezza sulla posizione assegnata e gli errori di sequenziamento possono indurre false varianti. È richiesto inoltre (in input), un database di varianti conosciute, per poter assegnare il genotipo di ciascuna variante attraverso le probabilità di ogni possibile genotipo calcolate sulla base dei dati osservati. Due tool conosciuti che applicano la pipeline standard sono  SAMtools o GATK (Genome Analysis Toolkit)\cite{McKenna2010gatk}. Questi approcci, tuttavia, sono computazionalmente costosi e richiedono molto tempo, speso soprattutto per effettuare l'allineamento di sequenza, poiché il calcolo di un accurato allineamento a più sequenze è un problema difficile e i metodi euristici non garantiscono il risultato ottimo; i metodi \textit{alignment-based} sono diventati quindi poco pratici per le applicazioni cliniche, dove il tempo è importante. Oltre al costo oneroso necessario per l'allineamento, ci sono altri problemi che devono essere ancora superati, come la presenza all'interno del genoma di grande variazione nel numero e nell'ordine degli elementi genetici a causa dei loro alti tassi di mutazione, frequenti eventi di ricombinazione genetica, duplicazioni di geni, riarrangiamenti che non possono essere allineati; queste procedure, d'altra parte, non sono facilmente scalabili e non si adattano bene alla grande mole di dati attuale; infine la loro sensibilità dipende dalla necessaria scelta iniziale dei parametri e pesi, è stato infatti dimostrato che piccole modifiche ai parametri di input possono influire notevolmente sull'allineamento. \\

\noindent
Infatti, i metodi privi di allineamento per l'analisi e il confronto di sequenze biologiche sono emersi per affrontare le sfide della comprensione dei modelli e delle proprietà delle sequenze biologiche. Si sono sviluppati e implementati nuovi metodi, denominati \textit{alignment-free} o \textit{mapping-free}, che sono in grado di effettuare la genotipizzazione di varianti senza l'utilizzo dell'allineamento delle read rispetto al genoma di riferimento e che quindi non si basano sulla programmazione dinamica e sono computazionalmente meno costosi. In particolare questi framework sfruttano diversi modelli e strutture dati efficienti per risolvere il problema, velocizzando di molto il tempo di esecuzione e ottenendo parallelamente percentuali di accuratezza comparabili ai tool \textit{alignment-based}, se non addirittura migliori; in alcuni casi ciò può comportare un utilizzo di memoria superiore. Esistono, inoltre, altri metodi definiti ``ibridi" di \textit{lightweight alignment} e \textit{pseudo-alignment}. 
I metodi senza allineamento sono resistenti agli eventi di mescolamento e ricombinazione e, a differenza dei metodi basati sull'allineamento, non dipendono da ipotesi iniziali. In generale, gli approcci \textit{alignment-free} sono matematicamente ben fondati nei campi dell'algebra lineare, della teoria dell'informazione e della meccanica statistica e calcolano misure a coppie di dissomiglianza o distanza tra sequenze o conteggi di frequenze di parole. Sfruttano diversi concetti per arrivare alla chiamata delle varianti ed ognuno è caratterizzato da una efficiente struttura dati e un algoritmo specifico, che solitamente implementa un modello probabilistico per determinare il genotipo più probabile; sono molto diversi tra loro, alcuni operano contando la frequenza di parole, \textit{k}-mer, come LAVA \cite{shajii2016lava} e VarGeno \cite{sun-medvedev2018vargeno}, suo diretto miglioramento, che procedono con il creare dei dizionari di \textit{k}-mer e ne valutano la frequenza.
%un dizionario sia per il genoma di riferimento che per l'elenco di SNP noti in input che associa ogni k-mer, una sequenza lunga \textit{k} nucleotidi, alle posizioni in cui appare e quindi chiamano le varianti dalle read valutando la frequenza dei \textit{k}-mer. Sono fino ad un ordine di grandezza più veloci dei tradizionali metodi basati sull'allineamento nel chiamare gli SNP, ma richiedono un'elevata quantità di memoria. 
Anche FastGT \cite{pajuste2017fastgt} si basa su k-mer per genotipizzare i dati di sequenziamento: la sua particolarità è l'efficace filtraggio del database precompilato di varianti bialleliche a singolo nucleotide (SNV) e corrispondenti k-mer. MALVA, anch'esso basato su parole, utilizza il concetto di firma o signature degli alleli, e determina i genotipi in base alla frequenza di tali firme nelle read. Esso è l'unico in grado di determinare anche indel di grandi dimensioni e varianti multi-alleliche, utilizzando una moderata quantità di memoria.

Altri metodi sono basati sull'assembly, come Cortex (Iqbal et al., 2012, De novo assembly and genotyping of variants using colored de Bruijn graphs) e DiscoSnp\texttt{++} \cite{peterlongo2017discosnp++} assemblano le read in grafi (es. grafi di \textit{de Bruijn}) e analizzano le bolle in questi grafi per rilevare le varianti. 

Altri ancora, basati sulla teoria dell'informazione, riconoscono e calcolano la quantità di informazioni condivise tra due sequenze biologiche analizzate. Inoltre, la strategia senza mappatura viene applicata anche per la scoperta di varianti \textit{de novo}.\\


\noindent
Come vedremo nel prossimo capitolo, è possibile effettuare una ulteriore distinzione all'interno dei framework \textit{mapping-free}, ovvero dividere i tool che utilizzano ugualmente un genoma di riferimento e una lista preassegnata di SNP noti in input per chiamare le varianti all'interno delle read del donatore, da quelli che riescono a identificare SNP e determinare il genotipo, senza l'utilizzo di una reference, metodi \textit{reference-free} o \textit{de novo}.\\




\noindent
Nella prossima sezione, verranno presentati singolarmente alcuni metodi \textit{alignment-free} scelti: verranno analizzati in dettaglio, per evidenziare, attraverso le strutture dati utilizzate e l'algoritmo, come essi siano efficienti e performanti. Quando necessario, saranno definite e illustrate particolari strutture dati, per una migliore comprensione dell'algoritmo.

Nella capitolo finale, verranno effettuate alcune considerazioni sulle prestazioni dei framework e, ove possibile, direttamente confrontati i framework proposti.


%LAVA \cite{shajii2016lava} e VarGeno \cite{sun-medvedev2018vargeno}, un suo diretto miglioramento, sono metodi basati su parole, fino ad un ordine di grandezza più veloci dei tradizionali metodi basati sull'allineamento nel chiamare gli SNP, ma che richiedono un'elevata quantità di memoria. La strategia è quella di creare un dizionario sia per il genoma di riferimento che per l'elenco di SNP noti in input che associ ogni k-mer, una sequenza lunga \textit{k} nucleotidi, alle posizioni in cui appare e quindi chiamare le varianti dalle read valutando la frequenza dei \textit{k}-mer. Anche FastGT \cite{pajuste2017fastgt} si basa su k-mer per genotipizzare i dati di sequenziamento: il database precompilato di varianti bialleliche a singolo nucleotide (SNV) e corrispondenti k-mer viene filtrato efficacemente.

%MALVA, anch'esso basato su parole, utilizza il concetto di firma o signature degli alleli, e determina i genotipi in base alla frequenza di tali firme nelle read. Esso è l'unico in grado di determinare anche indel di grandi dimensioni e varianti multi-alleliche, utilizzando una moderata quantità di memoria.

%Altri metodi basati sull'assembly come Cortex (Iqbal et al., 2012, De novo assembly and genotyping of variants using colored de Bruijn graphs) e DiscoSnp\texttt{++} \cite{peterlongo2017discosnp++} assemblano le read in grafi (es. grafi di \textit{de Bruijn}) e analizzano le bolle in questi grafi per rilevare le varianti. 

%Inoltre, la strategia senza mappatura viene applicata anche per la scoperta di varianti \textit{de novo}.\\




%Rilevare SNP (Single Nucleotide Polymorphisms) e mutazioni tra genomi sta diventando una pratica molto comune nell'ambito della NGS (Next-generation sequencing). In generale, i primi metodi di rilevamento SNP utilizzavano un genoma di riferimento: come precedentemente citato, i metodi basati sull'allineamento includono la mappatura delle read in input con il genoma di riferimento, una procedura costosa. 
%Pertanto negli ultimi anni sono stati proposti strumenti senza allineamento: la maggior parte degli attuali framework \textit{alignment free} utilizza ugualmente un genoma di riferimento e una lista preassegnata di SNP noti ed utilizza questi due input per chiamare le varianti all'interno delle read del donatore. Ci sono anche altri framework e modelli che riescono a identificare SNP e determinare il genotipo, senza l'utilizzo di una \textit{reference} e di cui parleremo in seguito.





\end{document}