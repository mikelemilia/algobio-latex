% Overview:
%   Introduzione TeX subfile for the project.
%   Each subfile MUST start with the following line
%		\documentclass[../main.tex]{subfiles}

\documentclass[../main.tex]{subfiles}

\begin{document}

\section{Introduzione}

\subsection{Il problema: la genotipizzazione e la rilevazione di mutazioni nel genoma}

L'obiettivo di questo progetto è analizzare lo stato dell'arte attuale per quanto riguarda il problema della ricerca di mutazioni (SNP) utilizzando metodi che non prevedono senza l'uso dell'allineamento (\textit{alignment-free}/\textit{mapping-free}). In particolare questo problema viene identificato con il termine di genotipizzazione, il processo per determinare quali varianti genetiche possiede un individuo.


Nell'ambito degli studi genetici, la scoperta e la caratterizzazione delle variazioni di sequenza nelle popolazioni umane è un'attività importante; in particolare è necessario analizzare in modo efficiente le variazioni di un individuo rispetto a un genoma di riferimento e ai dati disponibili sulle variazioni genomiche. 


Le variazioni analizzate possono essere di diverse tipologie: l'SNP, Single Nucleotide Polymorphisms, pronunciato snip, è un polimorfismo a singolo nucleotide, cioè una variazione rispetto ad un unico nucleotide, tale per cui l'allele polimorfico risulta presente nella popolazione in una proporzione superiore all'1\%; al di sotto di tale soglia si è soliti parlare di variante rara, SNV o Single-Nucleotide Variant in inglese, un'altro tipo di mutazione; gli indel sono inserzioni o eliminazioni di una o più basi all'interno del genoma; altre variazioni sono CNV, Copy Number Variation, fenomeno in cui diverse sezioni del genoma si ripetono in numero variabile e i riarrangiamenti. I diversi metodi e framework progettati per effettuare la genotipizzazione solitamente si concentrano su determinati tipi di mutazioni.


Attualmente le tecnologie NGS, Next-generation sequencing, sono largamente utilizzate per lo studio delle variazioni nel genoma: queste tecnologie permettono di sequenziare grandi genomi in un tempo ristretto e hanno la capacità di sequenziare, in parallelo, milioni di frammenti di DNA. I dati di sequenziamento, le read, vengono poi utilizzate come input per i diversi metodi di genotipizzazione.



\subsection{La pipeline standard e la tecnica \textit{mapping-free}}


La pipeline standard utilizzata per la genotipizzazione include l'allineamento delle read in input con una sequenza di riferimento, anch'essa in input, consentendo un certo numero di disallineamenti o indel. Le read mappate vengono quindi utilizzate per assegnare i genotipi; si utilizzano diversi strumenti di calcolo che valutano l'allineamento delle read in ogni posizione lungo il genoma e assegnano un punteggio di confidenza per indicare la probabilità dell'esistenza di una variante. Questo si ottiene usando algoritmi di inferenza statistica, che sono necessari perché gli allineamenti imperfetti creano incertezza sulla posizione assegnata a gli errore di sequenziamento possono indurre false varianti. Si richiede inoltre un database di varianti conosciute, per poi arrivare ad assegnare ciascun genotipo attraverso le probabilità di ogni possibile genotipo calcolate sulla base dei dati osservati. Due esempi di tool di questo tipo sono  SAMtools o GATK (Genome Analysis Toolkit) (McKenna et al., 2010, The genome analysis Toolkit: A MapReduce framework for
analyzing next-generation DNA sequencing data.) Questi approcci, tuttavia, sono computazionalmente costosi e richiedono molto tempo, speso soprattutto per effettuare l'allineamento di sequenza e sono diventati quindi poco pratici per le applicazioni cliniche, dove il tempo è importante. \\

\noindent
Si sono quindi sviluppati e implementati nuovi metodi denominati \textit{alignment-free} o \textit{mapping-free} che sono in grado di effettuare la genotipizzazione di varianti senza l'utilizzo dell'allineamento delle read rispetto al genoma di riferimento. In particolare questi framework sfruttano diversi modelli e strutture dati per risolvere il problema, velocizzando di molto il tempo di esecuzione e ottenendo allo stesso tempo percentuali di accuratezza comparabili ai tool \textit{alignment-based}, se non addirittura migliori; in alcuni casi ciò comporta un utilizzo di memoria superiore. Esistono inoltre altri metodi ``ibridi" di \textit{lightweight alignment} e \textit{pseudo-alignment}. Inoltre, come vedremo nei prossimi paragrafi, è possibile effettuare una ulteriore distinzione all'interno dei framework, ovvero dividere i tool che utilizzano in input, oltre alle read, anche un genoma di riferimento, da quelli che non necessitano del genoma di riferimento. 

I metodi che non ricorrono all'allineamento sfruttano diversi concetti per arrivare alla chiamata delle varianti ed ognuno è caratterizzato da una efficiente struttura dati e un algoritmo specifico, che solitamente implementa un modello probabilistico per determinare il genotipo più probabile. 

LAVA \cite{shajii2016lava} e VarGeno \cite{sun-medvedev2018vargeno}, un suo diretto miglioramento, sono metodi basati su parole, fino ad un ordine di grandezza più veloci dei tradizionali metodi basati sull'allineamento nel chiamare gli SNP, ma che richiedono un'elevata quantità di memoria. La strategia è quella di creare un dizionario sia per il genoma di riferimento che per l'elenco di SNP noti in input che associ ogni k-mer, una sequenza lunga k nucleotidi, alle posizioni in cui appare e quindi chiamare le varianti dalle read valutando la frequenza dei k mer. Anche FastGT \cite{pajuste2017fastgt} si basa su k-mer per genotipizzare i dati di sequenziamento: il database precompilato di varianti bialleliche a singolo nucleotide (SNV) e corrispondenti k-mer viene filtrato efficacemente.

MALVA, anch'esso basato su parole, utilizza il concetto di firma o signature degli alleli, e determina i genotipi in base alla frequenza di tali firme nelle read. Esso è l'unico in grado di determinare anche indel di grandi dimensioni e varianti multi-alleliche, utilizzando una moderata quantità di memoria.

Altri metodi basati sull'assembly come Cortex (Iqbal et al., 2012, De novo assembly and genotyping of variants using colored de Bruijn graphs) e DiscoSnp\texttt{++} \cite{peterlongo2017discosnp++} assemblano le read in grafi (es. grafi di \textit{de Bruijn}) e analizzano le bolle in questi grafi per rilevare le varianti. 

Inoltre, la strategia senza mappatura è stata applicata anche per la scoperta di varianti \textit{de novo}, varianti che esistono in un bambino ma non esistono in entrambi i suoi genitori.\\

\noindent
Nelle prossime sezioni di questo report, verranno presentati singolarmente alcuni metodi \textit{alignment-free} scelti: verranno analizzati in dettaglio, per evidenziare, attraverso le strutture dati utilizzate e l'algoritmo, come essi siano efficienti e performanti. Quando necessario, saranno definite e illustrate particolari strutture dati, necessarie alla migliore comprensione dell'algoritmo.

Nella fase finale, verranno effettuate alcune considerazioni sulle prestazioni dei framework e, ove possibile, direttamente confrontati i framework proposti.



\end{document}