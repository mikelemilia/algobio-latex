% Overview:
%   Introduzione TeX subfile for the project.
%   Each subfile MUST start with the following line
%		\documentclass[../main.tex]{subfiles}

\documentclass[../main.tex]{subfiles}

\begin{document}

\section{Introduzione} 

\subsection{Il problema: la genotipizzazione e la rilevazione di mutazioni nel genoma}

\textcolor{red}{Da modificare, 
\\aggiungere concetto coverage: La coverage è definita come il numero di basi di tutte le read brevi che corrispondono a un genoma diviso per la lunghezza di questo genoma.\\
aggiungere cosa sono tecnologie NGS, variante, genotipo} 

L'obiettivo di questo progetto è analizzare lo stato dell'arte attuale in merito al problema della ricerca di mutazioni (SNP) all'interno di un genoma prodotto dalle tecnologie di sequenziamento NGS utilizzando metodi che non prevedono l'uso dell'allineamento (\textit{alignment-free}/\textit{mapping-free}). In particolare questo problema viene identificato con il termine di genotipizzazione, il processo per determinare quali varianti genetiche possiede un individuo.

Nell'ambito degli studi genetici, la scoperta e la caratterizzazione delle variazioni di sequenza nelle popolazioni umane è un'attività importante; in particolare è necessario analizzare in modo efficiente le variazioni di un individuo rispetto a un genoma di riferimento e ai dati disponibili sulle variazioni genomiche. 

Le variazioni analizzate possono essere di diverse tipologie: l'SNP, Single Nucleotide Polymorphisms, pronunciato snip, è un polimorfismo a singolo nucleotide, cioè una variazione rispetto ad un unico nucleotide, tale per cui l'allele polimorfico risulta presente nella popolazione in una proporzione superiore all'1\%; al di sotto di tale soglia si è soliti parlare di variante rara, SNV o Single-Nucleotide Variant in inglese, un'altro tipo di mutazione; gli indel sono inserzioni o eliminazioni di una o più basi all'interno del genoma; altre variazioni sono CNV, Copy Number Variation, fenomeno in cui diverse sezioni del genoma si ripetono in numero variabile e i riarrangiamenti. I diversi metodi e framework progettati per effettuare la genotipizzazione solitamente si concentrano su determinati tipi di mutazioni.


Attualmente le tecnologie NGS, Next-generation sequencing, sono largamente utilizzate per lo studio delle variazioni nel genoma, in quanto permettono di sequenziare grandi genomi in un tempo ristretto e hanno la capacità di sequenziare, in parallelo, milioni di frammenti di DNA. I dati di sequenziamento, le read, vengono poi utilizzate come input per i diversi metodi di genotipizzazione.

\textcolor{OliveGreen}{\\ Rilevare SNP (Single Nucleotide Polymorphisms) e mutazioni tra genomi sta diventando una pratica molto comune nell'ambito della NGS (Next-generation sequencing). In generale, i primi metodi di rilevamento SNP utilizzavano un genoma di riferimento: come precedentemente citato, i metodi basati sull'allineamento includono la mappatura delle read in input con il genoma di riferimento, una procedura costosa. 
Pertanto negli ultimi anni sono stati proposti strumenti senza allineamento: la maggior parte degli attuali framework \textit{alignment free} utilizza ugualmente un genoma di riferimento e una lista preassegnata di SNP noti ed utilizza questi due input per chiamare le varianti all'interno delle read del donatore. Ci sono anche altri framework e modelli che riescono a identificare SNP e determinare il genotipo, senza l'utilizzo di una \textit{reference} e di cui parleremo in seguito (vedi Sezione \ref{rfm}).}


\subsection{La pipeline standard e la tecnica \textit{mapping-free}}


La pipeline standard utilizzata per la genotipizzazione include, in prima battuta, la possibilità di allineare le read in input con una sequenza di riferimento, anch'essa in input, consentendo un certo numero di disallineamenti o indel. Le read mappate vengono quindi utilizzate per assegnare i genotipi; per valutare l'allineamento delle read in ogni posizione lungo il genoma,  si utilizzano diversi strumenti di calcolo che assegnano un punteggio di confidenza per indicare la probabilità dell'esistenza di una variante. Questo si ottiene usando algoritmi di inferenza statistica, che sono necessari in quanto gli allineamenti imperfetti creano incertezza sulla posizione assegnata e gli errori di sequenziamento possono indurre false varianti. È richiesto inoltre \textcolor{OliveGreen}{(in input),} un database di varianti conosciute, per poter assegnare il genotipo di ciascuna variante attraverso le probabilità di ogni possibile genotipo calcolate sulla base dei dati osservati. Due tool che applicano la pipeline standar sono  SAMtools o GATK (Genome Analysis Toolkit) \textcolor{BurntOrange}{(McKenna et al., 2010, The genome analysis Toolkit: A MapReduce framework for analyzing next-generation DNA sequencing data.)} Questi approcci, tuttavia, sono computazionalmente costosi e richiedono molto tempo, speso soprattutto per effettuare l'allineamento di sequenza e sono diventati quindi poco pratici per le applicazioni cliniche, dove il tempo è importante. \\

\noindent
Si sono quindi sviluppati e implementati nuovi metodi denominati \textit{alignment-free} o \textit{mapping-free} che sono in grado di effettuare la genotipizzazione di varianti senza l'utilizzo dell'allineamento delle read rispetto al genoma di riferimento. In particolare questi framework sfruttano diversi modelli e strutture dati per risolvere il problema, velocizzando di molto il tempo di esecuzione e ottenendo allo stesso tempo percentuali di accuratezza comparabili ai tool \textit{alignment-based}, se non addirittura migliori; in alcuni casi ciò comporta un utilizzo di memoria superiore. Per ovviare a questio dispendio di memoria esistono altri metodi definiti ``ibridi" di \textit{lightweight alignment} e \textit{pseudo-alignment}. \textcolor{BurntOrange}{Inoltre, come vedremo nei prossimi paragrafi, è possibile effettuare una ulteriore distinzione all'interno dei framework, ovvero dividere i tool che utilizzano in input, oltre alle read, anche un genoma di riferimento, da quelli che non necessitano del genoma di riferimento.}

I metodi che non ricorrono all'allineamento sfruttano diversi concetti per arrivare alla chiamata delle varianti ed ognuno è caratterizzato da una efficiente struttura dati e un algoritmo specifico, che solitamente implementa un modello probabilistico per determinare il genotipo più probabile. 
\\\\
\textcolor{BurntOrange}{Da qui in giù è da rivedere, si può migliorare}

LAVA \cite{shajii2016lava} e VarGeno \cite{sun-medvedev2018vargeno}, un suo diretto miglioramento, sono metodi basati su parole, fino ad un ordine di grandezza più veloci dei tradizionali metodi basati sull'allineamento nel chiamare gli SNP, ma che richiedono un'elevata quantità di memoria. La strategia è quella di creare un dizionario sia per il genoma di riferimento che per l'elenco di SNP noti in input che associ ogni k-mer, una sequenza lunga \textit{k} nucleotidi, alle posizioni in cui appare e quindi chiamare le varianti dalle read valutando la frequenza dei \textit{k}-mer. Anche FastGT \cite{pajuste2017fastgt} si basa su k-mer per genotipizzare i dati di sequenziamento: il database precompilato di varianti bialleliche a singolo nucleotide (SNV) e corrispondenti k-mer viene filtrato efficacemente.

MALVA, anch'esso basato su parole, utilizza il concetto di firma o signature degli alleli, e determina i genotipi in base alla frequenza di tali firme nelle read. Esso è l'unico in grado di determinare anche indel di grandi dimensioni e varianti multi-alleliche, utilizzando una moderata quantità di memoria.

Altri metodi basati sull'assembly come Cortex (Iqbal et al., 2012, De novo assembly and genotyping of variants using colored de Bruijn graphs) e DiscoSnp\texttt{++} \cite{peterlongo2017discosnp++} assemblano le read in grafi (es. grafi di \textit{de Bruijn}) e analizzano le bolle in questi grafi per rilevare le varianti. 

Inoltre, la strategia senza mappatura è stata applicata anche per la scoperta di varianti \textit{de novo}, varianti che esistono in un bambino ma non esistono in entrambi i suoi genitori.\\

\noindent
Nelle prossime sezioni di questo report, verranno presentati singolarmente alcuni metodi \textit{alignment-free} scelti: verranno analizzati in dettaglio, per evidenziare, attraverso le strutture dati utilizzate e l'algoritmo, come essi siano efficienti e performanti. Quando necessario, saranno definite e illustrate particolari strutture dati, necessarie alla migliore comprensione dell'algoritmo.

Nella fase finale, verranno effettuate alcune considerazioni sulle prestazioni dei framework e, ove possibile, direttamente confrontati i framework proposti.



\end{document}